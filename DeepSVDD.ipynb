{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import easydict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST as MyMNIST\n",
    "from torchvision.datasets import CIFAR10 as MyCIFAR10\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1) dataset load시 필요한 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset load 할 때 전처리\n",
    "def global_constrast_normalization(x: torch.tensor, scale='11'):\n",
    "    assert scale in ('l1', 'l2')\n",
    "    n_features = int(np.prod(x.shape))\n",
    "    mean = torch.mean(x)\n",
    "    x -= mean\n",
    "\n",
    "    if scale == 'l1':\n",
    "        x_scale = torch.mean(torch.abs(x))\n",
    "\n",
    "    if scale == 'l2':\n",
    "        x_scale = torch.sqrt(torch.sum(x**2))/n_features\n",
    "\n",
    "    x /= x_scale\n",
    "\n",
    "    return x\n",
    "\n",
    "def get_target_label_idx(labels, targets):\n",
    "\n",
    "    return np.argwhere(np.isin(labels, targets)).flatten().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2) min-max-scaling한 결과를 리스트로 저장해두기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 5770153.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 157530.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1426388.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4066281.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:15<00:00, 11334498.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: global_constrast_normalization(x, scale='l1'))])\n",
    "\n",
    "mnist_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "cifar10_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "#mnist_dataset min-max-scaling\n",
    "min_max_mnist = []\n",
    "for class_label in range(10):\n",
    "    class_samples = [x for x, y in mnist_dataset if y == class_label]\n",
    "    class_samples = torch.cat(class_samples)\n",
    "\n",
    "    min_value = torch.min(class_samples)\n",
    "    max_value = torch.max(class_samples)\n",
    "    min_max_mnist.append((min_value.item(), max_value.item()))\n",
    "\n",
    "min_max_cifar10 = []\n",
    "for class_label in range(10):\n",
    "    # 현재 클래스에 대한 filter sample\n",
    "    class_samples = [x for x, y in cifar10_dataset if y == class_label]\n",
    "    class_samples = torch.cat(class_samples)\n",
    "\n",
    "    # min, max 계산\n",
    "    min_value = torch.min(class_samples)\n",
    "    max_value = torch.max(class_samples)\n",
    "    min_max_cifar10.append((min_value.item(), max_value.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.8826568126678467, 9.001545906066895),\n",
       " (-0.666146457195282, 20.108057022094727),\n",
       " (-0.7820455431938171, 11.665099143981934),\n",
       " (-0.764577329158783, 12.895051956176758),\n",
       " (-0.7253923416137695, 12.683235168457031),\n",
       " (-0.7698502540588379, 13.103279113769531),\n",
       " (-0.7784181237220764, 10.457836151123047),\n",
       " (-0.7129780650138855, 12.057777404785156),\n",
       " (-0.828040361404419, 10.581538200378418),\n",
       " (-0.7369959950447083, 10.697040557861328)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-28.94080924987793, 13.802960395812988),\n",
       " (-6.681769371032715, 9.158066749572754),\n",
       " (-34.92462158203125, 14.419297218322754),\n",
       " (-10.59916877746582, 11.093188285827637),\n",
       " (-11.945022583007812, 10.628044128417969),\n",
       " (-9.691973686218262, 8.94832706451416),\n",
       " (-9.174939155578613, 13.847018241882324),\n",
       " (-6.876684188842773, 12.28237247467041),\n",
       " (-15.603508949279785, 15.246490478515625),\n",
       " (-6.132884502410889, 8.046097755432129)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3) dataset 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "class MNIST_Dataset(Dataset):\n",
    "    def __init__(self, root: str, normal_class):\n",
    "        self.root = str(root)\n",
    "        self.n_classes = 2  # 0: normal, 1: outlier\n",
    "        self.normal_classes = tuple([normal_class])\n",
    "        self.outlier_classes = list(range(0, 10))\n",
    "        self.outlier_classes.remove(normal_class)\n",
    "\n",
    "        # MNIST preprocessing: GCN (with L1 norm) and min-max feature scaling to [0,1]\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Lambda(lambda x: global_constrast_normalization(x, scale='l1')),\n",
    "                                        transforms.Normalize([min_max_mnist[normal_class][0]],\n",
    "                                                             [min_max_mnist[normal_class][1] - min_max_mnist[normal_class][0]])])\n",
    "\n",
    "        target_transform = transforms.Lambda(lambda x: int(x in self.outlier_classes))\n",
    "\n",
    "        train_set = MyMNIST(root=self.root, train=True, download=True,\n",
    "                            transform=transform, target_transform=target_transform)\n",
    "        # Subset train_set to normal class\n",
    "        train_idx_normal = get_target_label_idx(train_set.targets, self.normal_classes)\n",
    "        self.train_set = Subset(train_set, train_idx_normal)\n",
    "\n",
    "        self.test_set = MyMNIST(root=self.root, train=False, download=True,\n",
    "                                transform=transform, target_transform=target_transform)\n",
    "\n",
    "    def loaders(self, batch_size: int, shuffle_train=True, shuffle_test=False, num_workers: int = 0) -> (\n",
    "            DataLoader, DataLoader):\n",
    "        train_loader = DataLoader(dataset=self.train_set, batch_size=batch_size, shuffle=shuffle_train,\n",
    "                                  num_workers=num_workers)\n",
    "        test_loader = DataLoader(dataset=self.test_set, batch_size=batch_size, shuffle=shuffle_test,\n",
    "                                 num_workers=num_workers)\n",
    "        return train_loader, test_loader\n",
    "\n",
    "\n",
    "class MyMNIST(MNIST):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyMNIST, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets()\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target, index  # only line changed\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "# CIFAR\n",
    "class CIFAR10_Dataset(Dataset):\n",
    "    def __init__(self, root: str, normal_class):\n",
    "        self.root = str(root)\n",
    "        self.n_classes = 2  # 0: normal, 1: outlier\n",
    "        self.normal_classes = tuple([normal_class])\n",
    "        self.outlier_classes = list(range(0, 10))\n",
    "        self.outlier_classes.remove(normal_class)\n",
    "\n",
    "        # CIFAR10 preprocessing: GCN (with L1 norm) and min-max feature scaling to [0,1]\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Lambda(lambda x: global_constrast_normalization(x, scale='l1')),\n",
    "                                        transforms.Normalize([min_max_cifar10[normal_class][0]] * 3,\n",
    "                                                             [min_max_cifar10[normal_class][1] - min_max_cifar10[normal_class][0]] * 3)])\n",
    "\n",
    "        target_transform = transforms.Lambda(lambda x: int(x in self.outlier_classes))\n",
    "\n",
    "        train_set = MyCIFAR10(root=self.root, train=True, download=True,\n",
    "                            transform=transform, target_transform=target_transform)\n",
    "        # Subset train_set to normal class\n",
    "        train_idx_normal = get_target_label_idx(train_set.targets, self.normal_classes)\n",
    "        self.train_set = Subset(train_set, train_idx_normal)\n",
    "\n",
    "        self.test_set = MyCIFAR10(root=self.root, train=False, download=True,\n",
    "                                transform=transform, target_transform=target_transform)\n",
    "\n",
    "    def loaders(self, batch_size: int, shuffle_train=True, shuffle_test=False, num_workers: int = 0) -> (\n",
    "            DataLoader, DataLoader):\n",
    "        train_loader = DataLoader(dataset=self.train_set, batch_size=batch_size, shuffle=shuffle_train,\n",
    "                                  num_workers=num_workers)\n",
    "        test_loader = DataLoader(dataset=self.test_set, batch_size=batch_size, shuffle=shuffle_test,\n",
    "                                 num_workers=num_workers)\n",
    "        return train_loader, test_loader\n",
    "\n",
    "\n",
    "class MyCIFAR10(CIFAR10):\n",
    "    \"\"\"Torchvision CIFAR10 class with patch of __getitem__ method to also return the index of a data sample.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyCIFAR10, self).__init__(*args, **kwargs)\n",
    "        self.train_data=self.data\n",
    "        self.train_labels=self.targets\n",
    "        self.test_data=self.data\n",
    "        self.test_labels=self.targets\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Override the original method of the CIFAR10 class.\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            triple: (image, target, index) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target, index  # only line changed\n",
    "\n",
    "\n",
    "def load_dataset(dataset_name, data_path, normal_class):\n",
    "\n",
    "    implemented_datasets = ('mnist', 'cifar10')\n",
    "    assert dataset_name in implemented_datasets\n",
    "\n",
    "    dataset = None\n",
    "\n",
    "    if dataset_name == 'mnist':\n",
    "        dataset = MNIST_Dataset(root=data_path, normal_class=normal_class)\n",
    "\n",
    "    if dataset_name == 'cifar10':\n",
    "        dataset = CIFAR10_Dataset(root=data_path, normal_class=normal_class)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1) dataset 별 model 구조 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class BaseNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(f\"Class name: {self.__class__.__name__}\")\n",
    "        self.rep_dim = None \n",
    "\n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def summary(self):\n",
    "\n",
    "        net_parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
    "        params = sum([np.prod(p.size()) for p in net_parameters])\n",
    "\n",
    "        print('Trainable parameters:', params)\n",
    "        print(self)\n",
    "\n",
    "# MNIST\n",
    "class MNIST_LeNet(BaseNet):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rep_dim = 32\n",
    "        self.fc1 = nn.Linear(4*7*7, self.rep_dim, bias = False)\n",
    "\n",
    "        self.layer1=nn.Sequential(\n",
    "            nn.Conv2d(1,8,5,bias=False,padding=2),\n",
    "            nn.BatchNorm2d(8, eps=1e-04, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.layer2=nn.Sequential(\n",
    "            nn.Conv2d(8,4,5,bias=False,padding=2),\n",
    "            nn.BatchNorm2d(4, eps=1e-04, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        return self.fc1(x)\n",
    "\n",
    "  \n",
    "class MNIST_LeNet_Autoencoder(BaseNet):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rep_dim = 32\n",
    "        self.fc1 = nn.Linear(4*7*7, self.rep_dim, bias = False)\n",
    "\n",
    "        self.layer1=nn.Sequential(\n",
    "            nn.Conv2d(1,8,5,bias=False,padding=2),\n",
    "            nn.BatchNorm2d(8, eps=1e-04, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.layer2=nn.Sequential(\n",
    "            nn.Conv2d(8,4,5,bias=False,padding=2),\n",
    "            nn.BatchNorm2d(4, eps=1e-04, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.layer3=nn.Sequential(\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose2d(2,4,5,bias=False,padding=2)\n",
    "        )\n",
    "\n",
    "        self.layer4=nn.Sequential(\n",
    "            nn.BatchNorm2d(4,eps=1e-04,affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose2d(4,8,5,bias=False,padding=3)\n",
    "        )\n",
    "\n",
    "        self.layer5=nn.Sequential(\n",
    "            nn.BatchNorm2d(8,eps=1e-04,affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose2d(8,1,5,bias=False,padding=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.fc1(x)\n",
    "        x=x.view(x.size(0),int(self.rep_dim/16),4,4)\n",
    "        x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "        x=self.layer5(x)\n",
    "        x=torch.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "###########################################################################################################\n",
    "\n",
    "# CIFAR\n",
    "class CIFAR10_LeNet(BaseNet):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rep_dim=128\n",
    "        self.fc1=nn.Linear(128 * 4 * 4, self.rep_dim, bias=False)\n",
    "\n",
    "        self.layer1=nn.Sequential(\n",
    "            nn.Conv2d(3,32,5,bias=False,padding=2),\n",
    "            nn.BatchNorm2d(32, eps=1e-04, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.layer2=nn.Sequential(\n",
    "            nn.Conv2d(32,64,5,bias=False,padding=2),\n",
    "            nn.BatchNorm2d(64, eps=1e-04, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.layer3=nn.Sequential(\n",
    "            nn.Conv2d(64,128,5,bias=False,padding=2),\n",
    "            nn.BatchNorm2d(128, eps=1e-04, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CIFAR10_LeNet_Autoencoder(BaseNet):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rep_dim=128\n",
    "        self.fc1=nn.Linear(128 * 4 * 4, self.rep_dim, bias=False)\n",
    "        self.bn1d = nn.BatchNorm1d(self.rep_dim, eps=1e-04, affine=False)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5, bias=False, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, bias=False, padding=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5, bias=False, padding=2)\n",
    "\n",
    "        self.layer1=nn.Sequential(\n",
    "            nn.Conv2d(3,32,5,bias=False,padding=2)\n",
    "        )\n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "\n",
    "        self.layer2=nn.Sequential(\n",
    "            nn.BatchNorm2d(32, eps=1e-04, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, bias=False, padding=2)\n",
    "        )\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "\n",
    "        self.layer3=nn.Sequential(\n",
    "            nn.BatchNorm2d(64, eps=1e-04, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 5, bias=False, padding=2)\n",
    "        )\n",
    "        nn.init.xavier_uniform_(self.conv3.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "\n",
    "        self.layer4=nn.Sequential(\n",
    "            nn.BatchNorm2d(128, eps=1e-04, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(int(self.rep_dim / (4 * 4)), 128, 5, bias=False, padding=2)\n",
    "        self.deconv2 = nn.ConvTranspose2d(128, 64, 5, bias=False, padding=2)\n",
    "        self.deconv3 = nn.ConvTranspose2d(64, 32, 5, bias=False, padding=2)\n",
    "        self.deconv4 = nn.ConvTranspose2d(32, 3, 5, bias=False, padding=2)\n",
    "\n",
    "        self.layer5=nn.Sequential(\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(int(self.rep_dim / (4 * 4)), 128, 5, bias=False, padding=2),\n",
    "            #nn.init.xavier_uniform_(self.deconv1.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        )\n",
    "        nn.init.xavier_uniform_(self.deconv1.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "\n",
    "        self.layer6=nn.Sequential(\n",
    "            nn.BatchNorm2d(128, eps=1e-04, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose2d(128, 64, 5, bias=False, padding=2),\n",
    "            #nn.init.xavier_uniform_(self.deconv2.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        )\n",
    "        nn.init.xavier_uniform_(self.deconv2.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "\n",
    "        self.layer7=nn.Sequential(\n",
    "            nn.BatchNorm2d(64, eps=1e-04, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose2d(64, 32, 5, bias=False, padding=2),\n",
    "            #nn.init.xavier_uniform_(self.deconv3.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        )\n",
    "        nn.init.xavier_uniform_(self.deconv3.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "\n",
    "        self.layer8=nn.Sequential(\n",
    "            nn.BatchNorm2d(32, eps=1e-04, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose2d(32, 3, 5, bias=False, padding=2),\n",
    "            #nn.init.xavier_uniform_(self.deconv4.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        )\n",
    "        nn.init.xavier_uniform_(self.deconv4.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.bn1d(self.fc1(x))\n",
    "        x=x.view(x.size(0), int(self.rep_dim / (4 * 4)), 4, 4)\n",
    "        x=self.layer5(x)\n",
    "        x=self.layer6(x)\n",
    "        x=self.layer7(x)\n",
    "        x=self.layer8(x)\n",
    "        x=torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2) dataset 별 model을 할당하는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net 할당    \n",
    "def build_network(net_name):\n",
    "\n",
    "    implemented_networks = ('mnist_LeNet', 'cifar10_LeNet')\n",
    "\n",
    "    assert net_name in implemented_networks\n",
    "\n",
    "    net = None\n",
    "\n",
    "    if net_name == 'mnist_LeNet':\n",
    "        net = MNIST_LeNet()\n",
    "\n",
    "    if net_name == 'cifar10_LeNet':\n",
    "        net = CIFAR10_LeNet()\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "#ae_net 할당\n",
    "def build_autoencoder(net_name):\n",
    "\n",
    "    implemented_networks = ('mnist_LeNet', 'cifar10_LeNet')\n",
    "    assert net_name in implemented_networks\n",
    "\n",
    "    ae_net = None\n",
    "\n",
    "    if net_name == 'mnist_LeNet':\n",
    "        ae_net = MNIST_LeNet_Autoencoder()\n",
    "\n",
    "    if net_name == 'cifar10_LeNet':\n",
    "        ae_net = CIFAR10_LeNet_Autoencoder()\n",
    "\n",
    "    return ae_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1) deepsvdd 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "dataset_model = 'cifar10'\n",
    "if dataset_model == 'mnist':\n",
    "    dataset_model = MNIST_Dataset\n",
    "elif dataset_model == 'cifar10':\n",
    "    dataset_model = CIFAR10_Dataset\n",
    "\n",
    "class BaseTrainer(ABC):\n",
    "\n",
    "    def __init__(self, optimizer_name: str, lr: float, n_epochs: int, lr_milestones: tuple,\n",
    "                 batch_size: int, weight_decay: float, device: str, n_jobs_dataloader: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.lr = lr\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr_milestones = lr_milestones\n",
    "        self.batch_size = batch_size\n",
    "        self.weight_decay = weight_decay\n",
    "        self.device = device\n",
    "        self.n_jobs_dataloader = n_jobs_dataloader\n",
    "\n",
    "\n",
    "        #여기 dataset 부분을 아예 없애고 밑에 train_loader를 받을 때 if문 추가해서 데이터셋별로 받으면 될듯..?\n",
    "        @abstractmethod\n",
    "        def train(self, dataset: dataset_model, net: BaseNet) -> BaseNet:\n",
    "            pass\n",
    "\n",
    "        @abstractmethod\n",
    "        def test(self, dataset: dataset_model, net: BaseNet):\n",
    "            pass\n",
    "\n",
    "\n",
    "class DeepSVDDTrainer(BaseTrainer):\n",
    "\n",
    "    def __init__(self, objective, R, c, nu: float, optimizer_name: str = 'adam', lr: float = 0.001,\n",
    "                 n_epochs: int = 150, lr_milestones: tuple = (), batch_size: int = 128, weight_decay: float = 1e-6,\n",
    "                 device: str = 'cuda', n_jobs_dataloader: int = 0):\n",
    "        super().__init__(optimizer_name, lr, n_epochs, lr_milestones, batch_size, weight_decay, device,\n",
    "                         n_jobs_dataloader)\n",
    "\n",
    "        assert objective in ('one-class', 'soft-boundary'), \"Objective must be either 'one-class' or 'soft-boundary'.\"\n",
    "        self.objective = objective\n",
    "\n",
    "        self.R = torch.tensor(R, device=self.device)  \n",
    "        self.c = torch.tensor(c, device=self.device) if c is not None else None\n",
    "        self.nu = nu\n",
    "\n",
    "        self.warm_up_n_epochs = 10 \n",
    "\n",
    "        self.train_time = None\n",
    "        self.test_auc = None\n",
    "        self.test_time = None\n",
    "        self.test_scores = None\n",
    "\n",
    "    def train(self, dataset: dataset_model, net: BaseNet):\n",
    "     \n",
    "        net = net.to(self.device)\n",
    "\n",
    "        train_loader, _ = dataset.loaders(batch_size=self.batch_size, num_workers=self.n_jobs_dataloader)\n",
    "\n",
    "        optimizer = optim.Adam(net.parameters(), lr=self.lr, weight_decay=self.weight_decay,\n",
    "                               amsgrad=self.optimizer_name == 'amsgrad')\n",
    "\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=self.lr_milestones, gamma=0.1)\n",
    "\n",
    "        if self.c is None:\n",
    "            print('Initializing center c...')\n",
    "            self.c = self.init_center_c(train_loader, net)\n",
    "            print('Center c initialized.')\n",
    "\n",
    "        print('====================Starting training====================')\n",
    "        start_time = time.time()\n",
    "        net.train()\n",
    "        for epoch in range(self.n_epochs):\n",
    "\n",
    "            scheduler.step()\n",
    "            if epoch in self.lr_milestones:\n",
    "                print('  LR scheduler: new learning rate is %g' % float(scheduler.get_lr()[0]))\n",
    "\n",
    "            loss_epoch = 0.0\n",
    "            n_batches = 0\n",
    "            epoch_start_time = time.time()\n",
    "            for data in train_loader:\n",
    "                inputs, _, _ = data\n",
    "                inputs = inputs.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                dist = torch.sum((outputs - self.c) ** 2, dim=1) \n",
    "                if self.objective == 'soft-boundary':\n",
    "                    scores = dist - self.R ** 2\n",
    "                    loss = self.R ** 2 + (1 / self.nu) * torch.mean(torch.max(torch.zeros_like(scores), scores))\n",
    "                else:\n",
    "                    loss = torch.mean(dist) \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if (self.objective == 'soft-boundary') and (epoch >= self.warm_up_n_epochs):\n",
    "                    self.R.data = torch.tensor(get_radius(dist, self.nu), device=self.device)\n",
    "\n",
    "                loss_epoch += loss.item()\n",
    "                n_batches += 1\n",
    "\n",
    "            epoch_train_time = time.time() - epoch_start_time\n",
    "\n",
    "            print('  Epoch {}/{}\\t Time: {:.3f}\\t Loss: {:.8f}'\n",
    "                        .format(epoch + 1, self.n_epochs, epoch_train_time, loss_epoch / n_batches))\n",
    "\n",
    "        self.train_time = time.time() - start_time\n",
    "        print('Training time: %.3f' % self.train_time)\n",
    "\n",
    "        print('====================Finished training====================')\n",
    "\n",
    "        return net\n",
    "\n",
    "    def test(self, dataset: dataset_model, net: BaseNet):\n",
    "     \n",
    "        net = net.to(self.device)\n",
    "\n",
    "        _, test_loader = dataset.loaders(batch_size=self.batch_size, num_workers=self.n_jobs_dataloader)\n",
    "\n",
    "        print('====================Starting testing====================')\n",
    "        start_time = time.time()\n",
    "        idx_label_score = []\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                inputs, labels, idx = data\n",
    "                inputs = inputs.to(self.device)\n",
    "                outputs = net(inputs)\n",
    "                dist = torch.sum((outputs - self.c) ** 2, dim=1)\n",
    "                if self.objective == 'soft-boundary':\n",
    "                    scores = dist - self.R ** 2\n",
    "                else:\n",
    "                    scores = dist\n",
    "\n",
    "                idx_label_score += list(zip(idx.cpu().data.numpy().tolist(),\n",
    "                                            labels.cpu().data.numpy().tolist(),\n",
    "                                            scores.cpu().data.numpy().tolist()))\n",
    "\n",
    "        self.test_time = time.time() - start_time\n",
    "        print('Testing time: %.3f' % self.test_time)\n",
    "\n",
    "        self.test_scores = idx_label_score\n",
    "\n",
    "        _, labels, scores = zip(*idx_label_score)\n",
    "        labels = np.array(labels)\n",
    "        scores = np.array(scores)\n",
    "\n",
    "        self.test_auc = roc_auc_score(labels, scores)\n",
    "        print('==================================================')\n",
    "        print('Test set AUC: {:.2f}%'.format(100. * self.test_auc))\n",
    "        print('==================================================')\n",
    "\n",
    "        print('==========Finished testing==========')\n",
    "\n",
    "    def init_center_c(self, train_loader: DataLoader, net: BaseNet, eps=0.1):\n",
    "        \"\"\"Initialize hypersphere center c as the mean from an initial forward pass on the data.\"\"\"\n",
    "        n_samples = 0\n",
    "        c = torch.zeros(net.rep_dim, device=self.device)\n",
    "\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in train_loader:\n",
    "                # get the inputs of the batch\n",
    "                inputs, _, _ = data\n",
    "                inputs = inputs.to(self.device)\n",
    "                outputs = net(inputs)\n",
    "                n_samples += outputs.shape[0]\n",
    "                c += torch.sum(outputs, dim=0)\n",
    "\n",
    "        c /= n_samples # c의 평균값 계산\n",
    "\n",
    "        # c가 0에 너무 가까운 경우를 처리\n",
    "        c[(abs(c) < eps) & (c < 0)] = -eps\n",
    "        c[(abs(c) < eps) & (c > 0)] = eps\n",
    "\n",
    "        return c\n",
    "\n",
    "#R 게산\n",
    "def get_radius(dist: torch.Tensor, nu: float):\n",
    "    \"\"\"Optimally solve for radius R via the (1-nu)-quantile of distances.\"\"\"\n",
    "    return np.quantile(np.sqrt(dist.clone().data.cpu().numpy()), 1 - nu)\n",
    "# 모든 원소에 대해 거리를 구한 후 계산된 제곱근 거리에 대해 (1-nu) 분위수를 계산.\n",
    "# 즉, 거리 분포에서 상위 (1-nu)%에 해당하는 거리를 찾음 -> 최종적으로 반환되는 반지름 R임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2) Pretrain(autoencoder) 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AETrainer(BaseTrainer):\n",
    "\n",
    "    def __init__(self, optimizer_name: str = 'adam', lr: float = 0.001, n_epochs: int = 150, lr_milestones: tuple = (),\n",
    "                 batch_size: int = 128, weight_decay: float = 1e-6, device: str = 'cuda', n_jobs_dataloader: int = 0):\n",
    "        super().__init__(optimizer_name, lr, n_epochs, lr_milestones, batch_size, weight_decay, device,\n",
    "                         n_jobs_dataloader)\n",
    "\n",
    "    def train(self, dataset: dataset_model, ae_net: BaseNet):\n",
    "        # logger = logging.getLogger()\n",
    "\n",
    "        # Set device for network\n",
    "        ae_net = ae_net.to(self.device)\n",
    "\n",
    "        # Get train data loader\n",
    "        train_loader, _ = dataset.loaders(batch_size=self.batch_size, num_workers=self.n_jobs_dataloader)\n",
    "\n",
    "        # Set optimizer (Adam optimizer for now)\n",
    "        optimizer = optim.Adam(ae_net.parameters(), lr=self.lr, weight_decay=self.weight_decay,\n",
    "                               amsgrad=self.optimizer_name == 'amsgrad')\n",
    "\n",
    "        # Set learning rate scheduler\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=self.lr_milestones, gamma=0.1)\n",
    "\n",
    "        # Training\n",
    "        # logger.info('Starting pretraining...')\n",
    "        print('==========Starting pretraining==========')\n",
    "        start_time = time.time()\n",
    "        ae_net.train() #autoencoder 학습시킴\n",
    "        for epoch in range(self.n_epochs):\n",
    "\n",
    "            scheduler.step()\n",
    "            if epoch in self.lr_milestones:\n",
    "                # logger.info('  LR scheduler: new learning rate is %g' % float(scheduler.get_lr()[0]))\n",
    "                print('  LR scheduler: new learning rate is %g' % float(scheduler.get_lr()[0]))\n",
    "\n",
    "            loss_epoch = 0.0\n",
    "            n_batches = 0\n",
    "            epoch_start_time = time.time()\n",
    "            for data in train_loader:\n",
    "                inputs, _, _ = data\n",
    "                inputs = inputs.to(self.device)\n",
    "\n",
    "                # Zero the network parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Update network parameters via backpropagation: forward + backward + optimize\n",
    "                outputs = ae_net(inputs)\n",
    "                scores = torch.sum((outputs - inputs) ** 2, dim=tuple(range(1, outputs.dim())))\n",
    "                loss = torch.mean(scores)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                loss_epoch += loss.item()\n",
    "                n_batches += 1\n",
    "\n",
    "            # log epoch statistics\n",
    "            epoch_train_time = time.time() - epoch_start_time\n",
    "            # logger.info('  Epoch {}/{}\\t Time: {:.3f}\\t Loss: {:.8f}'\n",
    "            #             .format(epoch + 1, self.n_epochs, epoch_train_time, loss_epoch / n_batches))\n",
    "            print('  Epoch {}/{}\\t Time: {:.3f}\\t Loss: {:.8f}'\n",
    "                        .format(epoch + 1, self.n_epochs, epoch_train_time, loss_epoch / n_batches))\n",
    "\n",
    "        pretrain_time = time.time() - start_time\n",
    "        # logger.info('Pretraining time: %.3f' % pretrain_time)\n",
    "        # logger.info('Finished pretraining.')\n",
    "\n",
    "        print('Pretraining time: %.3f' % pretrain_time)\n",
    "        print('==========Finished pretraining==========')\n",
    "\n",
    "        return ae_net\n",
    "\n",
    "    def test(self, dataset: dataset_model, ae_net: BaseNet):\n",
    "        # logger = logging.getLogger()\n",
    "\n",
    "        # Set device for network\n",
    "        ae_net = ae_net.to(self.device)\n",
    "\n",
    "        # Get test data loader\n",
    "        _, test_loader = dataset.loaders(batch_size=self.batch_size, num_workers=self.n_jobs_dataloader)\n",
    "\n",
    "        # Testing\n",
    "        # logger.info('Testing autoencoder...')\n",
    "        print('Testing autoencoder...')\n",
    "        loss_epoch = 0.0\n",
    "        n_batches = 0\n",
    "        start_time = time.time()\n",
    "        idx_label_score = []\n",
    "        ae_net.eval() #evaluate mode\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                inputs, labels, idx = data\n",
    "                inputs = inputs.to(self.device)\n",
    "                outputs = ae_net(inputs)\n",
    "                scores = torch.sum((outputs - inputs) ** 2, dim=tuple(range(1, outputs.dim())))\n",
    "                loss = torch.mean(scores)\n",
    "\n",
    "                # Save triple of (idx, label, score) in a list\n",
    "                idx_label_score += list(zip(idx.cpu().data.numpy().tolist(),\n",
    "                                            labels.cpu().data.numpy().tolist(),\n",
    "                                            scores.cpu().data.numpy().tolist()))\n",
    "\n",
    "                loss_epoch += loss.item()\n",
    "                n_batches += 1\n",
    "\n",
    "        # logger.info('Test set Loss: {:.8f}'.format(loss_epoch / n_batches))\n",
    "        print('Test set Loss: {:.8f}'.format(loss_epoch / n_batches))\n",
    "\n",
    "        _, labels, scores = zip(*idx_label_score)\n",
    "        labels = np.array(labels)\n",
    "        scores = np.array(scores)\n",
    "\n",
    "        auc = roc_auc_score(labels, scores)\n",
    "        # logger.info('Test set AUC: {:.2f}%'.format(100. * auc))\n",
    "        \n",
    "        print('Test set AUC: {:.2f}%'.format(100. * auc))\n",
    "\n",
    "        test_time = time.time() - start_time\n",
    "        # logger.info('Autoencoder testing time: %.3f' % test_time)\n",
    "        # logger.info('Finished testing autoencoder.')\n",
    "\n",
    "        print('Autoencoder testing time: %.3f' % test_time)\n",
    "        print('Finished testing autoencoder.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3) pretrain model과 deepsvdd를 합친 DeepSVDD class 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class DeepSVDD(object):\n",
    "\n",
    "    def __init__(self, objective: str = 'one-class', nu: float = 0.1):\n",
    "        \"\"\"Inits DeepSVDD with one of the two objectives and hyperparameter nu.\"\"\"\n",
    "\n",
    "        assert objective in ('one-class', 'soft-boundary'), \"Objective must be either 'one-class' or 'soft-boundary'.\"\n",
    "        self.objective = objective\n",
    "        assert (0 < nu) & (nu <= 1), \"For hyperparameter nu, it must hold: 0 < nu <= 1.\"\n",
    "        self.nu = nu\n",
    "        self.R = 0.0  # hypersphere radius R\n",
    "        self.c = None  # hypersphere center c\n",
    "\n",
    "        self.net_name = None\n",
    "        self.net = None  # neural network \\phi\n",
    "\n",
    "        self.trainer = None\n",
    "        self.optimizer_name = None\n",
    "\n",
    "        self.ae_net = None  # autoencoder network for pretraining\n",
    "        self.ae_trainer = None\n",
    "        self.ae_optimizer_name = None\n",
    "\n",
    "        self.results = {\n",
    "            'train_time': None,\n",
    "            'test_auc': None,\n",
    "            'test_time': None,\n",
    "            'test_scores': None,\n",
    "        }\n",
    "\n",
    "    def set_network(self, net_name):\n",
    "        \"\"\"Builds the neural network \\phi.\"\"\"\n",
    "        self.net_name = net_name\n",
    "        self.net = build_network(net_name)\n",
    "\n",
    "    def train(self, dataset: dataset_model, optimizer_name: str = 'adam', lr: float = 0.001, n_epochs: int = 100,\n",
    "              lr_milestones: tuple = (), batch_size: int = 128, weight_decay: float = 1e-6, device: str = 'cuda',\n",
    "              n_jobs_dataloader: int = 0):\n",
    "        \"\"\"Trains the Deep SVDD model on the training data.\"\"\"\n",
    "\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.trainer = DeepSVDDTrainer(self.objective, self.R, self.c, self.nu, optimizer_name, lr=lr,\n",
    "                                       n_epochs=n_epochs, lr_milestones=lr_milestones, batch_size=batch_size,\n",
    "                                       weight_decay=weight_decay, device=device, n_jobs_dataloader=n_jobs_dataloader)\n",
    "        # Get the model\n",
    "        self.net = self.trainer.train(dataset, self.net)\n",
    "        self.R = float(self.trainer.R.cpu().data.numpy())  # get float\n",
    "        self.c = self.trainer.c.cpu().data.numpy().tolist()  # get list\n",
    "        self.results['train_time'] = self.trainer.train_time\n",
    "\n",
    "    def test(self, dataset: dataset_model, device: str = 'cuda', n_jobs_dataloader: int = 0):\n",
    "        \"\"\"Tests the Deep SVDD model on the test data.\"\"\"\n",
    "\n",
    "        if self.trainer is None:\n",
    "            self.trainer = DeepSVDDTrainer(self.objective, self.R, self.c, self.nu,\n",
    "                                           device=device, n_jobs_dataloader=n_jobs_dataloader)\n",
    "\n",
    "        self.trainer.test(dataset, self.net)\n",
    "        # Get results\n",
    "        self.results['test_auc'] = self.trainer.test_auc\n",
    "        self.results['test_time'] = self.trainer.test_time\n",
    "        self.results['test_scores'] = self.trainer.test_scores\n",
    "\n",
    "    def pretrain(self, dataset: dataset_model, optimizer_name: str = 'adam', lr: float = 0.001, n_epochs: int = 150,\n",
    "                 lr_milestones: tuple = (), batch_size: int = 128, weight_decay: float = 1e-6, device: str = 'cuda',\n",
    "                 n_jobs_dataloader: int = 0):\n",
    "        \"\"\"Pretrains the weights for the Deep SVDD network \\phi via autoencoder.\"\"\"\n",
    "\n",
    "        self.ae_net = build_autoencoder(self.net_name)\n",
    "        self.ae_optimizer_name = optimizer_name\n",
    "        self.ae_trainer = AETrainer(optimizer_name, lr=lr, n_epochs=n_epochs, lr_milestones=lr_milestones,\n",
    "                                    batch_size=batch_size, weight_decay=weight_decay, device=device,\n",
    "                                    n_jobs_dataloader=n_jobs_dataloader)\n",
    "        self.ae_net = self.ae_trainer.train(dataset, self.ae_net)\n",
    "        self.ae_trainer.test(dataset, self.ae_net)\n",
    "        self.init_network_weights_from_pretraining()\n",
    "\n",
    "    def init_network_weights_from_pretraining(self):\n",
    "        \"\"\"Initialize the Deep SVDD network weights from the encoder weights of the pretraining autoencoder.\"\"\"\n",
    "\n",
    "        net_dict = self.net.state_dict()\n",
    "        ae_net_dict = self.ae_net.state_dict()\n",
    "\n",
    "        # Filter out decoder network keys\n",
    "        ae_net_dict = {k: v for k, v in ae_net_dict.items() if k in net_dict}\n",
    "        # Overwrite values in the existing state_dict\n",
    "        net_dict.update(ae_net_dict)\n",
    "        # Load the new state_dict\n",
    "        self.net.load_state_dict(net_dict)\n",
    "\n",
    "    def save_model(self, export_model, save_ae=True):\n",
    "        \"\"\"Save Deep SVDD model to export_model.\"\"\"\n",
    "\n",
    "        net_dict = self.net.state_dict()\n",
    "        ae_net_dict = self.ae_net.state_dict() if save_ae else None\n",
    "\n",
    "        torch.save({'R': self.R,\n",
    "                    'c': self.c,\n",
    "                    'net_dict': net_dict,\n",
    "                    'ae_net_dict': ae_net_dict}, export_model)\n",
    "\n",
    "    def load_model(self, model_path, load_ae=False):\n",
    "        \"\"\"Load Deep SVDD model from model_path.\"\"\"\n",
    "\n",
    "        model_dict = torch.load(model_path)\n",
    "\n",
    "        self.R = model_dict['R']\n",
    "        self.c = model_dict['c']\n",
    "        self.net.load_state_dict(model_dict['net_dict'])\n",
    "        if load_ae:\n",
    "            if self.ae_net is None:\n",
    "                self.ae_net = build_autoencoder(self.net_name)\n",
    "            self.ae_net.load_state_dict(model_dict['ae_net_dict'])\n",
    "\n",
    "    def save_results(self, export_json):\n",
    "        \"\"\"Save results dict to a JSON-file.\"\"\"\n",
    "        with open(export_json, 'w') as fp:\n",
    "            json.dump(self.results, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-4) code 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def load_config(import_json, settings):\n",
    "    \"\"\"Load settings dict from import_json (path/filename.json) JSON-file.\"\"\"\n",
    "    with open(import_json, 'r') as fp:\n",
    "        loaded_settings = json.load(fp)\n",
    "    settings.update(loaded_settings)\n",
    "\n",
    "def save_config(export_json, settings):\n",
    "    \"\"\"Save settings dict to export_json (path/filename.json) JSON-file.\"\"\"\n",
    "    with open(export_json, 'w') as fp:\n",
    "        json.dump(settings, fp, indent=0)\n",
    "\n",
    "def main(dataset_name, net_name, xp_path, data_path, load_config, load_model, objective, nu, device, seed,\n",
    "         optimizer_name, lr, n_epochs, lr_milestone, batch_size, weight_decay, pretrain, ae_optimizer_name, ae_lr,\n",
    "         ae_n_epochs, ae_lr_milestone, ae_batch_size, ae_weight_decay, n_jobs_dataloader, normal_class):\n",
    "\n",
    "    settings = {\n",
    "        'dataset_name': dataset_name,\n",
    "        'net_name': net_name,\n",
    "        'xp_path': xp_path,\n",
    "        'data_path': data_path,\n",
    "        'load_config': load_config,\n",
    "        'load_model': load_model,\n",
    "        'objective': objective,\n",
    "        'nu': nu,\n",
    "        'device': device,\n",
    "        'seed': seed,\n",
    "        'optimizer_name': optimizer_name,\n",
    "        'lr': lr,\n",
    "        'n_epochs': n_epochs,\n",
    "        'lr_milestone': lr_milestone,\n",
    "        'batch_size': batch_size,\n",
    "        'weight_decay': weight_decay,\n",
    "        'pretrain': pretrain,\n",
    "        'ae_optimizer_name': ae_optimizer_name,\n",
    "        'ae_lr': ae_lr,\n",
    "        'ae_n_epochs': ae_n_epochs,\n",
    "        'ae_lr_milestone': ae_lr_milestone,\n",
    "        'ae_batch_size': ae_batch_size,\n",
    "        'ae_weight_decay': ae_weight_decay,\n",
    "        'n_jobs_dataloader': n_jobs_dataloader,\n",
    "        'normal_class': normal_class\n",
    "    }\n",
    "\n",
    "    print('Data path is %s.' % data_path)\n",
    "    print('Export path is %s.' % xp_path)\n",
    "\n",
    "    print('Dataset: %s' % dataset_name)\n",
    "    print('Normal class: %d' % normal_class)\n",
    "    print('Network: %s' % net_name)\n",
    "\n",
    "    if load_config:\n",
    "        load_config(import_json=load_config, settings=settings)\n",
    "        print('Loaded configuration from %s.' % load_config)\n",
    "\n",
    "    print('Deep SVDD objective: %s' % settings['objective'])\n",
    "    print('Nu-paramerter: %.2f' % settings['nu'])\n",
    "\n",
    "    if settings['seed'] != -1:\n",
    "        random.seed(settings['seed'])\n",
    "        np.random.seed(settings['seed'])\n",
    "        torch.manual_seed(settings['seed'])\n",
    "        print('Set seed to %d.' % settings['seed'])\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        device = 'cpu'\n",
    "    print('Computation device: %s' % device)\n",
    "    print('Number of dataloader workers: %d' % n_jobs_dataloader)\n",
    "\n",
    "    # Load data\n",
    "    dataset = load_dataset(settings['dataset_name'], settings['data_path'], settings['normal_class'])\n",
    "\n",
    "    # Initialize DeepSVDD model and set neural network \\phi\n",
    "    deep_SVDD = DeepSVDD(settings['objective'], settings['nu'])\n",
    "    deep_SVDD.set_network(settings['net_name'])\n",
    "\n",
    "    if settings['load_model']:\n",
    "        deep_SVDD.load_model(model_path=settings['load_model'], load_ae=True)\n",
    "        print('Loading model from %s.' % settings['load_model'])\n",
    "\n",
    "    print('Pretraining: %s' % settings['pretrain']) #True일때 실행됨\n",
    "    if settings['pretrain']:\n",
    "        print('Pretraining optimizer: %s' % settings['ae_optimizer_name'])\n",
    "        print('Pretraining learning rate: %g' % settings['ae_lr'])\n",
    "        print('Pretraining epochs: %d' % settings['ae_n_epochs'])\n",
    "        print('Pretraining learning rate scheduler milestones: %s' % (settings['ae_lr_milestone'],))\n",
    "        print('Pretraining batch size: %d' % settings['ae_batch_size'])\n",
    "        print('Pretraining weight decay: %g' % settings['ae_weight_decay'])\n",
    "\n",
    "        deep_SVDD.pretrain(dataset,\n",
    "                           optimizer_name=settings['ae_optimizer_name'],\n",
    "                           lr=settings['ae_lr'],\n",
    "                           n_epochs=settings['ae_n_epochs'],\n",
    "                           lr_milestones=settings['ae_lr_milestone'],\n",
    "                           batch_size=settings['ae_batch_size'],\n",
    "                           weight_decay=settings['ae_weight_decay'],\n",
    "                           device=device,\n",
    "                           n_jobs_dataloader=n_jobs_dataloader)\n",
    "        \n",
    "\n",
    "    print('Training optimizer: %s' % settings['optimizer_name'])\n",
    "    print('Training learning rate: %g' % settings['lr'])\n",
    "    print('Training epochs: %d' % settings['n_epochs'])\n",
    "    print('Training learning rate scheduler milestones: %s' % (settings['lr_milestone'],))\n",
    "    print('Training batch size: %d' % settings['batch_size'])\n",
    "    print('Training weight decay: %g' % settings['weight_decay'])\n",
    "\n",
    "    deep_SVDD.train(dataset,\n",
    "                    optimizer_name=settings['optimizer_name'],\n",
    "                    lr=settings['lr'],\n",
    "                    n_epochs=settings['n_epochs'],\n",
    "                    lr_milestones=settings['lr_milestone'],\n",
    "                    batch_size=settings['batch_size'],\n",
    "                    weight_decay=settings['weight_decay'],\n",
    "                    device=device,\n",
    "                    n_jobs_dataloader=n_jobs_dataloader)\n",
    "\n",
    "    deep_SVDD.test(dataset, device=device, n_jobs_dataloader=n_jobs_dataloader)\n",
    "\n",
    "    indices, labels, scores = zip(*deep_SVDD.results['test_scores'])\n",
    "    indices, labels, scores = np.array(indices), np.array(labels), np.array(scores)\n",
    "    idx_sorted = indices[labels == 0][np.argsort(scores[labels == 0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path is <module 'torchvision.datasets' from '/home/yulim/anaconda3/envs/conda_yl/lib/python3.12/site-packages/torchvision/datasets/__init__.py'>.\n",
      "Export path is /home/yulim/practice/July_two/deep_path.\n",
      "Dataset: cifar10\n",
      "Normal class: 5\n",
      "Network: cifar10_LeNet\n",
      "Deep SVDD objective: one-class\n",
      "Nu-paramerter: 0.10\n",
      "Computation device: cuda\n",
      "Number of dataloader workers: 0\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to <module 'torchvision.datasets' from '/home/yulim/anaconda3/envs/conda_yl/lib/python3.12/site-packages/torchvision/datasets/__init__.py'>/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:16<00:00, 10652000.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting <module 'torchvision.datasets' from '/home/yulim/anaconda3/envs/conda_yl/lib/python3.12/site-packages/torchvision/datasets/__init__.py'>/cifar-10-python.tar.gz to <module 'torchvision.datasets' from '/home/yulim/anaconda3/envs/conda_yl/lib/python3.12/site-packages/torchvision/datasets/__init__.py'>\n",
      "Files already downloaded and verified\n",
      "Class name: CIFAR10_LeNet\n",
      "Pretraining: True\n",
      "Pretraining optimizer: adam\n",
      "Pretraining learning rate: 0.001\n",
      "Pretraining epochs: 150\n",
      "Pretraining learning rate scheduler milestones: [50]\n",
      "Pretraining batch size: 200\n",
      "Pretraining weight decay: 1e-06\n",
      "Class name: CIFAR10_LeNet_Autoencoder\n",
      "==========Starting pretraining==========\n",
      "  Epoch 1/150\t Time: 2.168\t Loss: 32.92889698\n",
      "  Epoch 2/150\t Time: 1.272\t Loss: 13.52946056\n",
      "  Epoch 3/150\t Time: 1.272\t Loss: 11.40113205\n",
      "  Epoch 4/150\t Time: 1.272\t Loss: 9.30803047\n",
      "  Epoch 5/150\t Time: 1.272\t Loss: 8.13268585\n",
      "  Epoch 6/150\t Time: 1.271\t Loss: 7.36031593\n",
      "  Epoch 7/150\t Time: 1.273\t Loss: 6.84963139\n",
      "  Epoch 8/150\t Time: 1.272\t Loss: 6.48252628\n",
      "  Epoch 9/150\t Time: 1.268\t Loss: 6.22348597\n",
      "  Epoch 10/150\t Time: 1.273\t Loss: 5.86584295\n",
      "  Epoch 11/150\t Time: 1.273\t Loss: 5.55724390\n",
      "  Epoch 12/150\t Time: 1.271\t Loss: 5.37929197\n",
      "  Epoch 13/150\t Time: 1.270\t Loss: 5.26752495\n",
      "  Epoch 14/150\t Time: 1.272\t Loss: 5.03559938\n",
      "  Epoch 15/150\t Time: 1.274\t Loss: 4.92189669\n",
      "  Epoch 16/150\t Time: 1.272\t Loss: 4.84985769\n",
      "  Epoch 17/150\t Time: 1.273\t Loss: 4.73259851\n",
      "  Epoch 18/150\t Time: 1.273\t Loss: 4.53340359\n",
      "  Epoch 19/150\t Time: 1.272\t Loss: 4.48471493\n",
      "  Epoch 20/150\t Time: 1.269\t Loss: 4.50457474\n",
      "  Epoch 21/150\t Time: 1.269\t Loss: 4.38459505\n",
      "  Epoch 22/150\t Time: 1.273\t Loss: 4.28444590\n",
      "  Epoch 23/150\t Time: 1.274\t Loss: 4.16194912\n",
      "  Epoch 24/150\t Time: 1.272\t Loss: 4.12799376\n",
      "  Epoch 25/150\t Time: 1.269\t Loss: 4.03374161\n",
      "  Epoch 26/150\t Time: 1.269\t Loss: 3.95112961\n",
      "  Epoch 27/150\t Time: 1.268\t Loss: 3.93143073\n",
      "  Epoch 28/150\t Time: 1.272\t Loss: 3.88087932\n",
      "  Epoch 29/150\t Time: 1.273\t Loss: 3.87264424\n",
      "  Epoch 30/150\t Time: 1.273\t Loss: 3.76350198\n",
      "  Epoch 31/150\t Time: 1.272\t Loss: 3.76766638\n",
      "  Epoch 32/150\t Time: 1.273\t Loss: 3.72667289\n",
      "  Epoch 33/150\t Time: 1.272\t Loss: 3.65141195\n",
      "  Epoch 34/150\t Time: 1.273\t Loss: 3.63602443\n",
      "  Epoch 35/150\t Time: 1.273\t Loss: 3.63285911\n",
      "  Epoch 36/150\t Time: 1.276\t Loss: 3.67112169\n",
      "  Epoch 37/150\t Time: 1.276\t Loss: 3.98346046\n",
      "  Epoch 38/150\t Time: 1.272\t Loss: 3.71940172\n",
      "  Epoch 39/150\t Time: 1.273\t Loss: 3.54714108\n",
      "  Epoch 40/150\t Time: 1.272\t Loss: 3.45217623\n",
      "  Epoch 41/150\t Time: 1.271\t Loss: 3.48159547\n",
      "  Epoch 42/150\t Time: 1.271\t Loss: 3.40958116\n",
      "  Epoch 43/150\t Time: 1.273\t Loss: 3.39252325\n",
      "  Epoch 44/150\t Time: 1.273\t Loss: 3.39585245\n",
      "  Epoch 45/150\t Time: 1.273\t Loss: 3.38255896\n",
      "  Epoch 46/150\t Time: 1.271\t Loss: 3.33520617\n",
      "  Epoch 47/150\t Time: 1.273\t Loss: 3.34882766\n",
      "  Epoch 48/150\t Time: 1.270\t Loss: 3.31300935\n",
      "  Epoch 49/150\t Time: 1.273\t Loss: 3.24725186\n",
      "  Epoch 50/150\t Time: 1.272\t Loss: 3.13490566\n",
      "  LR scheduler: new learning rate is 0.0001\n",
      "  Epoch 51/150\t Time: 1.271\t Loss: 3.10012893\n",
      "  Epoch 52/150\t Time: 1.273\t Loss: 3.09575027\n",
      "  Epoch 53/150\t Time: 1.274\t Loss: 3.09064950\n",
      "  Epoch 54/150\t Time: 1.273\t Loss: 3.08940019\n",
      "  Epoch 55/150\t Time: 1.274\t Loss: 3.08271687\n",
      "  Epoch 56/150\t Time: 1.273\t Loss: 3.08843530\n",
      "  Epoch 57/150\t Time: 1.273\t Loss: 3.08503262\n",
      "  Epoch 58/150\t Time: 1.271\t Loss: 3.08696157\n",
      "  Epoch 59/150\t Time: 1.273\t Loss: 3.08207489\n",
      "  Epoch 60/150\t Time: 1.274\t Loss: 3.06563545\n",
      "  Epoch 61/150\t Time: 1.274\t Loss: 3.06316241\n",
      "  Epoch 62/150\t Time: 1.274\t Loss: 3.06371139\n",
      "  Epoch 63/150\t Time: 1.273\t Loss: 3.06608325\n",
      "  Epoch 64/150\t Time: 1.272\t Loss: 3.06023970\n",
      "  Epoch 65/150\t Time: 1.271\t Loss: 3.05978669\n",
      "  Epoch 66/150\t Time: 1.273\t Loss: 3.06823139\n",
      "  Epoch 67/150\t Time: 1.273\t Loss: 3.06719239\n",
      "  Epoch 68/150\t Time: 1.276\t Loss: 3.04713860\n",
      "  Epoch 69/150\t Time: 1.272\t Loss: 3.06679373\n",
      "  Epoch 70/150\t Time: 1.282\t Loss: 3.04118657\n",
      "  Epoch 71/150\t Time: 1.273\t Loss: 3.04847572\n",
      "  Epoch 72/150\t Time: 1.272\t Loss: 3.04972301\n",
      "  Epoch 73/150\t Time: 1.271\t Loss: 3.02925950\n",
      "  Epoch 74/150\t Time: 1.273\t Loss: 3.03105669\n",
      "  Epoch 75/150\t Time: 1.273\t Loss: 3.02331972\n",
      "  Epoch 76/150\t Time: 1.271\t Loss: 3.02831118\n",
      "  Epoch 77/150\t Time: 1.271\t Loss: 3.01708703\n",
      "  Epoch 78/150\t Time: 1.271\t Loss: 3.03880453\n",
      "  Epoch 79/150\t Time: 1.270\t Loss: 3.02599647\n",
      "  Epoch 80/150\t Time: 1.272\t Loss: 3.03023222\n",
      "  Epoch 81/150\t Time: 1.264\t Loss: 3.01367586\n",
      "  Epoch 82/150\t Time: 1.256\t Loss: 3.02024824\n",
      "  Epoch 83/150\t Time: 1.258\t Loss: 3.01991531\n",
      "  Epoch 84/150\t Time: 1.259\t Loss: 3.00723844\n",
      "  Epoch 85/150\t Time: 1.259\t Loss: 3.00444965\n",
      "  Epoch 86/150\t Time: 1.261\t Loss: 2.99958216\n",
      "  Epoch 87/150\t Time: 1.259\t Loss: 2.99352893\n",
      "  Epoch 88/150\t Time: 1.259\t Loss: 3.00042421\n",
      "  Epoch 89/150\t Time: 1.259\t Loss: 2.98469656\n",
      "  Epoch 90/150\t Time: 1.260\t Loss: 2.98847255\n",
      "  Epoch 91/150\t Time: 1.261\t Loss: 2.99702315\n",
      "  Epoch 92/150\t Time: 1.259\t Loss: 2.97425978\n",
      "  Epoch 93/150\t Time: 1.259\t Loss: 2.98707846\n",
      "  Epoch 94/150\t Time: 1.261\t Loss: 2.98901512\n",
      "  Epoch 95/150\t Time: 1.259\t Loss: 2.97114819\n",
      "  Epoch 96/150\t Time: 1.261\t Loss: 2.97229905\n",
      "  Epoch 97/150\t Time: 1.259\t Loss: 2.95843756\n",
      "  Epoch 98/150\t Time: 1.259\t Loss: 2.96279890\n",
      "  Epoch 99/150\t Time: 1.261\t Loss: 2.96096329\n",
      "  Epoch 100/150\t Time: 1.260\t Loss: 2.95898517\n",
      "  Epoch 101/150\t Time: 1.261\t Loss: 2.95297754\n",
      "  Epoch 102/150\t Time: 1.259\t Loss: 2.95436674\n",
      "  Epoch 103/150\t Time: 1.260\t Loss: 2.94507724\n",
      "  Epoch 104/150\t Time: 1.259\t Loss: 2.95456940\n",
      "  Epoch 105/150\t Time: 1.260\t Loss: 2.94617324\n",
      "  Epoch 106/150\t Time: 1.261\t Loss: 2.93635101\n",
      "  Epoch 107/150\t Time: 1.260\t Loss: 2.92905441\n",
      "  Epoch 108/150\t Time: 1.261\t Loss: 2.91479524\n",
      "  Epoch 109/150\t Time: 1.261\t Loss: 2.93732646\n",
      "  Epoch 110/150\t Time: 1.265\t Loss: 2.92000165\n",
      "  Epoch 111/150\t Time: 1.263\t Loss: 2.91321323\n",
      "  Epoch 112/150\t Time: 1.263\t Loss: 2.90663713\n",
      "  Epoch 113/150\t Time: 1.260\t Loss: 2.91352436\n",
      "  Epoch 114/150\t Time: 1.261\t Loss: 2.90573109\n",
      "  Epoch 115/150\t Time: 1.263\t Loss: 2.89496227\n",
      "  Epoch 116/150\t Time: 1.263\t Loss: 2.91901373\n",
      "  Epoch 117/150\t Time: 1.262\t Loss: 2.91647205\n",
      "  Epoch 118/150\t Time: 1.264\t Loss: 2.89683995\n",
      "  Epoch 119/150\t Time: 1.261\t Loss: 2.90675290\n",
      "  Epoch 120/150\t Time: 1.262\t Loss: 2.90142684\n",
      "  Epoch 121/150\t Time: 1.264\t Loss: 2.88428163\n",
      "  Epoch 122/150\t Time: 1.262\t Loss: 2.88107465\n",
      "  Epoch 123/150\t Time: 1.262\t Loss: 2.86910611\n",
      "  Epoch 124/150\t Time: 1.262\t Loss: 2.87377952\n",
      "  Epoch 125/150\t Time: 1.260\t Loss: 2.85730377\n",
      "  Epoch 126/150\t Time: 1.262\t Loss: 2.86227505\n",
      "  Epoch 127/150\t Time: 1.260\t Loss: 2.86662875\n",
      "  Epoch 128/150\t Time: 1.261\t Loss: 2.87734239\n",
      "  Epoch 129/150\t Time: 1.264\t Loss: 2.85310563\n",
      "  Epoch 130/150\t Time: 1.262\t Loss: 2.84721898\n",
      "  Epoch 131/150\t Time: 1.261\t Loss: 2.83958501\n",
      "  Epoch 132/150\t Time: 1.264\t Loss: 2.83918065\n",
      "  Epoch 133/150\t Time: 1.261\t Loss: 2.85065019\n",
      "  Epoch 134/150\t Time: 1.261\t Loss: 2.84854577\n",
      "  Epoch 135/150\t Time: 1.261\t Loss: 2.82094590\n",
      "  Epoch 136/150\t Time: 1.262\t Loss: 2.83014590\n",
      "  Epoch 137/150\t Time: 1.261\t Loss: 2.83905313\n",
      "  Epoch 138/150\t Time: 1.261\t Loss: 2.82671563\n",
      "  Epoch 139/150\t Time: 1.261\t Loss: 2.81297814\n",
      "  Epoch 140/150\t Time: 1.261\t Loss: 2.80710007\n",
      "  Epoch 141/150\t Time: 1.262\t Loss: 2.81894348\n",
      "  Epoch 142/150\t Time: 1.261\t Loss: 2.80968782\n",
      "  Epoch 143/150\t Time: 1.261\t Loss: 2.82084247\n",
      "  Epoch 144/150\t Time: 1.262\t Loss: 2.79874238\n",
      "  Epoch 145/150\t Time: 1.262\t Loss: 2.80133574\n",
      "  Epoch 146/150\t Time: 1.263\t Loss: 2.79223966\n",
      "  Epoch 147/150\t Time: 1.261\t Loss: 2.76121266\n",
      "  Epoch 148/150\t Time: 1.262\t Loss: 2.80319522\n",
      "  Epoch 149/150\t Time: 1.260\t Loss: 2.78330997\n",
      "  Epoch 150/150\t Time: 1.263\t Loss: 2.77646795\n",
      "Pretraining time: 190.965\n",
      "==========Finished pretraining==========\n",
      "Testing autoencoder...\n",
      "Test set Loss: 3.52767599\n",
      "Test set AUC: 61.12%\n",
      "Autoencoder testing time: 2.083\n",
      "Finished testing autoencoder.\n",
      "Training optimizer: adam\n",
      "Training learning rate: 0.001\n",
      "Training epochs: 100\n",
      "Training learning rate scheduler milestones: [50]\n",
      "Training batch size: 200\n",
      "Training weight decay: 1e-06\n",
      "Initializing center c...\n",
      "Center c initialized.\n",
      "====================Starting training====================\n",
      "  Epoch 1/100\t Time: 1.124\t Loss: 76.23477291\n",
      "  Epoch 2/100\t Time: 1.114\t Loss: 2.48439542\n",
      "  Epoch 3/100\t Time: 1.116\t Loss: 0.47722768\n",
      "  Epoch 4/100\t Time: 1.112\t Loss: 0.24121147\n",
      "  Epoch 5/100\t Time: 1.112\t Loss: 0.18164751\n",
      "  Epoch 6/100\t Time: 1.114\t Loss: 0.14960970\n",
      "  Epoch 7/100\t Time: 1.115\t Loss: 0.12823750\n",
      "  Epoch 8/100\t Time: 1.117\t Loss: 0.11152555\n",
      "  Epoch 9/100\t Time: 1.115\t Loss: 0.09962116\n",
      "  Epoch 10/100\t Time: 1.117\t Loss: 0.08911904\n",
      "  Epoch 11/100\t Time: 1.115\t Loss: 0.08144865\n",
      "  Epoch 12/100\t Time: 1.117\t Loss: 0.07463153\n",
      "  Epoch 13/100\t Time: 1.117\t Loss: 0.06926659\n",
      "  Epoch 14/100\t Time: 1.116\t Loss: 0.06477519\n",
      "  Epoch 15/100\t Time: 1.115\t Loss: 0.05984151\n",
      "  Epoch 16/100\t Time: 1.116\t Loss: 0.05604133\n",
      "  Epoch 17/100\t Time: 1.118\t Loss: 0.05291862\n",
      "  Epoch 18/100\t Time: 1.114\t Loss: 0.05018431\n",
      "  Epoch 19/100\t Time: 1.114\t Loss: 0.04805660\n",
      "  Epoch 20/100\t Time: 1.115\t Loss: 0.04548630\n",
      "  Epoch 21/100\t Time: 1.115\t Loss: 0.04254963\n",
      "  Epoch 22/100\t Time: 1.114\t Loss: 0.04166828\n",
      "  Epoch 23/100\t Time: 1.115\t Loss: 0.03867645\n",
      "  Epoch 24/100\t Time: 1.116\t Loss: 0.03686794\n",
      "  Epoch 25/100\t Time: 1.114\t Loss: 0.03588381\n",
      "  Epoch 26/100\t Time: 1.113\t Loss: 0.03545371\n",
      "  Epoch 27/100\t Time: 1.114\t Loss: 0.03412597\n",
      "  Epoch 28/100\t Time: 1.114\t Loss: 0.03265063\n",
      "  Epoch 29/100\t Time: 1.114\t Loss: 0.03135258\n",
      "  Epoch 30/100\t Time: 1.114\t Loss: 0.02971259\n",
      "  Epoch 31/100\t Time: 1.113\t Loss: 0.03162598\n",
      "  Epoch 32/100\t Time: 1.113\t Loss: 0.02896152\n",
      "  Epoch 33/100\t Time: 1.114\t Loss: 0.02852712\n",
      "  Epoch 34/100\t Time: 1.112\t Loss: 0.02787249\n",
      "  Epoch 35/100\t Time: 1.113\t Loss: 0.02630086\n",
      "  Epoch 36/100\t Time: 1.116\t Loss: 0.02563909\n",
      "  Epoch 37/100\t Time: 1.110\t Loss: 0.02610744\n",
      "  Epoch 38/100\t Time: 1.112\t Loss: 0.02625336\n",
      "  Epoch 39/100\t Time: 1.113\t Loss: 0.02371021\n",
      "  Epoch 40/100\t Time: 1.114\t Loss: 0.02319099\n",
      "  Epoch 41/100\t Time: 1.112\t Loss: 0.02282019\n",
      "  Epoch 42/100\t Time: 1.113\t Loss: 0.02253311\n",
      "  Epoch 43/100\t Time: 1.115\t Loss: 0.02176523\n",
      "  Epoch 44/100\t Time: 1.113\t Loss: 0.02107246\n",
      "  Epoch 45/100\t Time: 1.113\t Loss: 0.02161837\n",
      "  Epoch 46/100\t Time: 1.112\t Loss: 0.02081177\n",
      "  Epoch 47/100\t Time: 1.115\t Loss: 0.02083350\n",
      "  Epoch 48/100\t Time: 1.117\t Loss: 0.02104801\n",
      "  Epoch 49/100\t Time: 1.116\t Loss: 0.02162870\n",
      "  Epoch 50/100\t Time: 1.117\t Loss: 0.01779472\n",
      "  LR scheduler: new learning rate is 0.0001\n",
      "  Epoch 51/100\t Time: 1.114\t Loss: 0.01539868\n",
      "  Epoch 52/100\t Time: 1.116\t Loss: 0.01521333\n",
      "  Epoch 53/100\t Time: 1.114\t Loss: 0.01515639\n",
      "  Epoch 54/100\t Time: 1.113\t Loss: 0.01513343\n",
      "  Epoch 55/100\t Time: 1.111\t Loss: 0.01511737\n",
      "  Epoch 56/100\t Time: 1.115\t Loss: 0.01503423\n",
      "  Epoch 57/100\t Time: 1.117\t Loss: 0.01501369\n",
      "  Epoch 58/100\t Time: 1.117\t Loss: 0.01501185\n",
      "  Epoch 59/100\t Time: 1.115\t Loss: 0.01495759\n",
      "  Epoch 60/100\t Time: 1.116\t Loss: 0.01491585\n",
      "  Epoch 61/100\t Time: 1.121\t Loss: 0.01487150\n",
      "  Epoch 62/100\t Time: 1.116\t Loss: 0.01483776\n",
      "  Epoch 63/100\t Time: 1.115\t Loss: 0.01473670\n",
      "  Epoch 64/100\t Time: 1.116\t Loss: 0.01467006\n",
      "  Epoch 65/100\t Time: 1.114\t Loss: 0.01463326\n",
      "  Epoch 66/100\t Time: 1.115\t Loss: 0.01471450\n",
      "  Epoch 67/100\t Time: 1.117\t Loss: 0.01462696\n",
      "  Epoch 68/100\t Time: 1.132\t Loss: 0.01458567\n",
      "  Epoch 69/100\t Time: 1.118\t Loss: 0.01453784\n",
      "  Epoch 70/100\t Time: 1.118\t Loss: 0.01449502\n",
      "  Epoch 71/100\t Time: 1.115\t Loss: 0.01444863\n",
      "  Epoch 72/100\t Time: 1.117\t Loss: 0.01439087\n",
      "  Epoch 73/100\t Time: 1.115\t Loss: 0.01437232\n",
      "  Epoch 74/100\t Time: 1.123\t Loss: 0.01433567\n",
      "  Epoch 75/100\t Time: 1.137\t Loss: 0.01423858\n",
      "  Epoch 76/100\t Time: 1.133\t Loss: 0.01418864\n",
      "  Epoch 77/100\t Time: 1.128\t Loss: 0.01417038\n",
      "  Epoch 78/100\t Time: 1.128\t Loss: 0.01413156\n",
      "  Epoch 79/100\t Time: 1.128\t Loss: 0.01405294\n",
      "  Epoch 80/100\t Time: 1.130\t Loss: 0.01408572\n",
      "  Epoch 81/100\t Time: 1.129\t Loss: 0.01395660\n",
      "  Epoch 82/100\t Time: 1.130\t Loss: 0.01396349\n",
      "  Epoch 83/100\t Time: 1.130\t Loss: 0.01389744\n",
      "  Epoch 84/100\t Time: 1.130\t Loss: 0.01382087\n",
      "  Epoch 85/100\t Time: 1.127\t Loss: 0.01380931\n",
      "  Epoch 86/100\t Time: 1.131\t Loss: 0.01382026\n",
      "  Epoch 87/100\t Time: 1.129\t Loss: 0.01379854\n",
      "  Epoch 88/100\t Time: 1.129\t Loss: 0.01364678\n",
      "  Epoch 89/100\t Time: 1.128\t Loss: 0.01359619\n",
      "  Epoch 90/100\t Time: 1.128\t Loss: 0.01361551\n",
      "  Epoch 91/100\t Time: 1.129\t Loss: 0.01350490\n",
      "  Epoch 92/100\t Time: 1.134\t Loss: 0.01346930\n",
      "  Epoch 93/100\t Time: 1.129\t Loss: 0.01335325\n",
      "  Epoch 94/100\t Time: 1.129\t Loss: 0.01341743\n",
      "  Epoch 95/100\t Time: 1.128\t Loss: 0.01334002\n",
      "  Epoch 96/100\t Time: 1.127\t Loss: 0.01328273\n",
      "  Epoch 97/100\t Time: 1.127\t Loss: 0.01318058\n",
      "  Epoch 98/100\t Time: 1.128\t Loss: 0.01314856\n",
      "  Epoch 99/100\t Time: 1.126\t Loss: 0.01308590\n",
      "  Epoch 100/100\t Time: 1.127\t Loss: 0.01306317\n",
      "Training time: 111.889\n",
      "====================Finished training====================\n",
      "====================Starting testing====================\n",
      "Testing time: 2.018\n",
      "==================================================\n",
      "Test set AUC: 61.23%\n",
      "==================================================\n",
      "==========Finished testing==========\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(dataset_name='cifar10', net_name='cifar10_LeNet', xp_path='/home/yulim/practice/July_two/deep_path', data_path=datasets, load_config=None, load_model=None, \n",
    "         objective='one-class', nu=0.1, device='cuda', seed=-1,optimizer_name='adam', lr=1e-3, n_epochs=100, lr_milestone=[50], batch_size=200, weight_decay=1e-6, \n",
    "         pretrain=True, ae_optimizer_name='adam', ae_lr=1e-3,ae_n_epochs=150, ae_lr_milestone=[50], ae_batch_size=200, ae_weight_decay=1e-6, n_jobs_dataloader=0, normal_class=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
